{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This is a document used to record some of the most common used function for Data Analytics in Python**"
      ],
      "metadata": {
        "id": "xDKM67t_Dnbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analytics Cheatsheet"
      ],
      "metadata": {
        "id": "UWorLWNlD-n2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "MZ75ePXgEMqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Library\n",
        "import pandas as pd #pandas for data wrangling/preparation\n",
        "import missingno as msno #Python library for the exploratory visualization of missing data\n",
        "import matplotlib.pyplot as plt #library for matplotlib visualization\n",
        "import matplotlib.dates as mdates #for time series plot\n",
        "import seaborn as sns #library for seaborn visualization\n",
        "sns.set(font_scale = 1.2, style = 'ticks')\n",
        "import plotly.express as px #library for plotly visualization\n",
        "from pylab import rcParams \n",
        "rcParams['figure.figsize'] = 10,8 #setting default size of the plot"
      ],
      "metadata": {
        "id": "PM1mbZJSEGmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "5w50fwjChUq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define file path\n",
        "file_path = \"/content/Seagate_v5.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "d7vNGDZthXoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Wrangliing"
      ],
      "metadata": {
        "id": "PFC9i9w8D5IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dimension/head/shape/info\n",
        "len(df)\n",
        "df.head()\n",
        "df.info()\n",
        "\n",
        "# Check individual values for missing values\n",
        "print(df.isna())\n",
        "\n",
        "# Check each column for missing values\n",
        "print(df.isna().any())\n",
        "\n",
        "# Bar plot of missing values by variable\n",
        "df.isna().sum().plot(kind = 'bar')\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n",
        "# Show missing values\n",
        "msno.matrix(df)\n",
        "\n",
        "# Handling missing value\n",
        "# Drop columns if needed\n",
        "index_list = [1,2,3,4,5] # columns that needed to be dropped\n",
        "df.drop(df.columns[index_list], axis = 1, inplace = True)\n",
        "\n",
        "# filter cols\n",
        "#filtering as per the above note\n",
        "ppp_business_df = df[df['BusinessType'].isin(['Corporation', 'Limited  Liability Company(LLC)','Subchapter S Corporation', 'Non-Profit Organization'])]\n",
        "\n",
        "## method 1. Drop na\n",
        "df = df.dropna()\n",
        "## check again\n",
        "print(df.isn.any())\n",
        "\n",
        "## method 2. replace NA value\n",
        "# List the columns with missing values\n",
        "cols_with_missing = [\"small_sold\", \"large_sold\", \"xl_sold\"] # define your missing columns here\n",
        "# Create histograms showing the distributions cols_with_missing\n",
        "df[cols_with_missing].hist() # check the dist\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# fill the na\n",
        "value = 0\n",
        "df = df.fillna(value)\n",
        "# Create histograms showing the distributions cols_with_missing\n",
        "df[cols_with_missing].hist() # check the dist\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Processing step\n",
        "# change datatype to datetype\n",
        "col_list = ['a','b'] # column names\n",
        "df[col_list] = df[col_list].apply(pd.to_datetime)\n",
        "\n",
        "# Check duplicate\n",
        "df.duplicated().sum()\n",
        "\n",
        "# Check the unique levels in each column \n",
        "for column in df.columns:\n",
        "    unique_levels = df[column].unique()\n",
        "    print(f\"Unique levels in {column}: {unique_levels}\")\n",
        "\n",
        "# stat summary with describe()\n",
        "df.describe()\n",
        "\n",
        "# Extract clean data\n",
        "output_path = \"./public_150k_plus_cleaned.csv\"\n",
        "df.to_csv(output_path)\n",
        "\n",
        "# Aggregate function\n",
        "# min(), max(), mean(), median()\n",
        "# df['col'].min()\n",
        "\n",
        "# create categories from origianl col, with cut()\n",
        "# min is 150K and max is 10M, so now I will create a category for a range of loan amount.\n",
        "df['LoanRange'] = pd.cut(df['CurrentApprovalAmount'], \n",
        "                             bins = [0, 350000, 1000000, 2000000, 5000000, float('inf')], \n",
        "                             labels = ['Less than 350K', '350K - 1M', '1M - 2M', '2M - 5M', 'More than 5M'])\n",
        "\n",
        "# Sorting \n",
        "df_sorted = df.sort_values('col',asceding = False)"
      ],
      "metadata": {
        "id": "4v_OMKKpDl9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data visualization"
      ],
      "metadata": {
        "id": "eC7omdqBsdRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize category data with seaborn, cat plot\n",
        "col = 'column_name'\n",
        "sns.catplot(data = df, y = col, kind = 'count', palette = 'blues',  height = 7, aspect = 1.5)\n",
        "plt.title('Loan Amount Category Wise Count')\n",
        "plt.ylabel('Loan Range')\n",
        "plt.show()\n",
        "\n",
        "# histogram with sns\n",
        "sns.histplot(data = df, x = 'JobsReported', bins = 50, color = 'LightBlue')\n",
        "plt.title('Overall Employee Count')\n",
        "plt.xlabel('Jobs Reported')\n",
        "\n",
        "# groupby(), follow by aggregation function\n",
        "gb_df = df.groupby('col').sum()\n",
        "\n",
        "# Bar plot\n",
        "# Vizualizing Loan Category with Employees Count\n",
        "sns.barplot(data = df, x = 'LoanRange', y = 'JobsReported', color = 'darkblue')\n",
        "plt.title('Loan Category with Employee Count')\n",
        "plt.ylabel('Jobs Reported')\n",
        "plt.xlabel('Loan Range')\n",
        "\n",
        "#lets view the top 5 states on a bar plot.\n",
        "sns.barplot(data = df, x = 'CurrentApprovalAmount', y = 'BorrowerState', \n",
        "            order = df.sort_values('CurrentApprovalAmount', ascending = False)[:5]['BorrowerState'],\n",
        "           color = 'LightBlue')\n",
        "plt.title('Top 5 States with Highest Loan Amount')\n",
        "plt.xlabel('Loan Amount (In 10 Billions)')\n",
        "\n",
        "# Countplot\n",
        "# Lets check the top 5 Loan Lenders\n",
        "sns.countplot(data = ppp_df, y = 'OriginatingLender', \n",
        "              order = ppp_df['OriginatingLender'].value_counts().index[:5], color = 'Green')\n",
        "\n",
        "# Map Vis with plotly\n",
        "# Vizualizing the state data on map plot by plotly.\n",
        "px.choropleth(df, locations = 'BorrowerState', color = 'CurrentApprovalAmount',\n",
        "              locationmode = 'USA-states', scope = 'usa', \n",
        "              color_continuous_scale = 'plasma_r',\n",
        "              title = 'State wise loan amount borrowed', labels = {'BorrowerState': 'State', 'CurrentApprovalAmount': 'Total Loan Amount'})\n"
      ],
      "metadata": {
        "id": "bC7_XYXTsYVk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}